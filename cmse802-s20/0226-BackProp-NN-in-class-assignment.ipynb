{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to successfully complete this assignment you need to participate both individually and in groups during class on **Wednesday February 26**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Class Assignment: Artificial Neural Network\n",
    "\n",
    "</p>\n",
    "\n",
    "<img src= \"https://images.theconversation.com/files/168081/original/file-20170505-21003-zbguhy.jpg?ixlib=rb-1.1.0&q=45&auto=format&w=926&fit=clip\" width=\"50%\">\n",
    "\n",
    "From: [theconversation.com](http://theconversation.com/deep-learning-and-neural-networks-77259)\n",
    "\n",
    "In class today we summarize the steps involved in designing and training a feed-forward artificial neural network. We will use the python script file named [partSix.py](./partSix.py) file provided in the \"Neural Networks Demystified\" module which can be downloaded from github:\n",
    "\n",
    "    git clone https://github.com/stephencwelch/Neural-Networks-Demystified\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda for today's class (80 minutes) \n",
    "\n",
    "**Note:** This will likely take more than one day in class.  So we actually have 220 minutes. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</p>\n",
    "\n",
    "1. [(10 minutes) Review pre-class assignment](#Review_pre-class_assignment)\n",
    "1. [(20 minutes) Working with Scripts](#Working_with_Scripts)\n",
    "1. [(20 minutes) Modify code to be more flexible](#Modify_code_to_be_more_flexible)\n",
    "1. [(20 minutes) Use our ANN on the \"Digits\" dataset](#ANN_and_Digits)\n",
    "1. [(30 minutes) Finding/Using Neural Networks Libraries](#NN_Libraries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"Review_pre-class_assignment\"></a>\n",
    "# 1. Review pre-class assignment\n",
    "\n",
    "* [0225-BackProp-NN-pre-class-assignment](0225-BackProp-NN-pre-class-assignment.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"Working_with_Scripts\"></a>\n",
    "# 2. Working with Scripts\n",
    "\n",
    "Lets talk about working with scripts. The following example loads the partSix script into and imports everything. Although I hate this syntax, lets use it for now.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data [[0.3 1. ]\n",
      " [0.5 0.2]\n",
      " [1.  0.4]]\n",
      "Output Data [[0.75]\n",
      " [0.82]\n",
      " [0.93]]\n"
     ]
    }
   ],
   "source": [
    "from partSix import * #Reminder, your instructor hates this syntax\n",
    "print(\"Input Data\", X)\n",
    "print(\"Output Data\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making a new Neural Network\n",
      "Untrained Output [[0.20445666]\n",
      " [0.28278159]\n",
      " [0.26468668]]\n"
     ]
    }
   ],
   "source": [
    "#Untrained Random Network\n",
    "NN = Neural_Network()\n",
    "y1 = NN.forward(X)\n",
    "print(\"Untrained Output\", y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 100\n",
      "         Function evaluations: 112\n",
      "         Gradient evaluations: 112\n"
     ]
    }
   ],
   "source": [
    "#Training step\n",
    "T = trainer(NN)\n",
    "T.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Output [[0.74998719]\n",
      " [0.81997369]\n",
      " [0.92998639]]\n"
     ]
    }
   ],
   "source": [
    "#Trained Network\n",
    "y2 = NN.forward(X)\n",
    "print(\"Trained Output\",y2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>DO THIS:</font>** Calculate and compare the mean Euclidean error for untrained network (```y1```) and the trained network (```y2```). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"Modify_code_to_be_more_flexible\"></a>\n",
    "\n",
    "# 3. Modify code to be more flexible\n",
    "\n",
    "The code for our Neural Network example above assumes an input layer size of 2, hidden layer size of 3 and an output layer size of 1.  We are going to now modify [partSix.py](partSix.py) to update the ```__init___``` function to take three inputs; input layers (```ILS```), output layers (```OLS```) and Hidden Layers (```HLS```).\n",
    "\n",
    "## Step 1: code review\n",
    "\n",
    "&#9989; **<font color=red>DO THIS:</font>** As a class let's review the parts of the partSix.py file and see if we can understand what everything is doing.\n",
    "\n",
    "\n",
    "## Step 2: rewrite/override the ```__init__``` function\n",
    "\n",
    "&#9989; **<font color=red>DO THIS:</font>** Lets try to improve the code in above so that the user can specify these as inputs when creating the Neural_Network object.  The new code should work such that the default values should stay the same. Rerun the above example to make sure it still works. The new syntax should be something like the following. The new defaults should make the following code work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'ILS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-47c394cb7722>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeural_Network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mILS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mHLS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'ILS'"
     ]
    }
   ],
   "source": [
    "NN = Neural_Network(ILS=64,OLS=1,HLS=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT SIDE NOTE:** it can be tricky modifying imported scripts and testing them inside of jupyter notebooks. The reason is that Jupyter will only import a package once.  Consider the following simple example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing testimport.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testimport.py\n",
    "\n",
    "# Creat a really simple script called testimport.py\n",
    "print(\"importing testimport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell creates a file called [testimport.py](testimport.py) in your current directory. The following code will import (aka run) the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing testimport\n"
     ]
    }
   ],
   "source": [
    "import testimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import testimport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how only one of the import commands will execute the print statement. This is because jupyter thinks that testimport.py is already imported and assumes that it did not change so does not bother importing it a second time.  If you modify a file you need to go to the \"Kernel\" menu and select \"Restart & Clear Output\" which will reset the entire Kernel. Then run the notebook again from scratch.\n",
    "\n",
    "The following line is a bash command that should delete the ```testimport.py``` file so it will not clutter your directory. Note a quick way to run bash commands from inside jupyter notebooks (actually python in general) is to use the exclamation mark ```!```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm testimport.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"ANN_and_Digits\"></a>\n",
    "# 4. Use our ANN on the \"Digits\" dataset.\n",
    "\n",
    "Here is the code copied from the Machine Learning Module which downloads the \"digits\" dataset and should separates it into training and testing sets. However there may be an error on your machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.cross_validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2a3fb0bcd5df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_lfw_people\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_digits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msk_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_digits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cross_validation'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_lfw_people, load_digits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "sk_data = load_digits();\n",
    "\n",
    "#Cool slider to browse all of the images.\n",
    "from ipywidgets import interact\n",
    "def browse_images(images, labels, categories):\n",
    "    n = len(images)\n",
    "    def view_image(i):\n",
    "        plt.imshow(images[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        plt.title('%s' % categories[labels[i]])\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    interact(view_image, i=(0,n-1))\n",
    "browse_images(sk_data.images, sk_data.target, sk_data.target_names)\n",
    "\n",
    "\n",
    "feature_vectors = sk_data.data\n",
    "class_labels = sk_data.target\n",
    "categories = sk_data.target_names\n",
    "\n",
    "N, h, w = sk_data.images.shape\n",
    "train_vectors, test_vectors, train_labels, test_labels = train_test_split(feature_vectors, class_labels, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>DO THIS:</font>** Assuming you get an error, Google the error and fix the above code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>DO THIS:</font>** Now, assuming we got the above functions to work properly, the following code reformats the digets data into vectors we can use in our new neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = np.ndarray((len(train_labels),1))\n",
    "for i in range(len(train_labels)):\n",
    "    train2[i] = train_labels[i]/10\n",
    "train_labels = train2\n",
    "\n",
    "test2 = np.ndarray((len(test_labels),1))\n",
    "for i in range(len(test_labels)):\n",
    "    test2[i] = test_labels[i]/10\n",
    "test_labels = test2\n",
    "\n",
    "test_vectors = test_vectors/256\n",
    "train_vectors = train_vectors/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'ILS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9359cc4fb73b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Run the training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeural_Network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mILS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mHLS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'ILS'"
     ]
    }
   ],
   "source": [
    "#Run the training. \n",
    "NN = Neural_Network(ILS=64,OLS=1,HLS=3)\n",
    "T = trainer(NN)\n",
    "T.train(train_vectors, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = NN.forward(train_vectors)\n",
    "\n",
    "print(\"Training Data error\", np.sum(np.sqrt((train_labels - pred_labels)*(train_labels-pred_labels)))/len(train_vectors)*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = NN.forward(test_vectors)\n",
    "\n",
    "print(\"Testing Data error\", np.sum(np.sqrt((test_labels - pred_labels)*(test_labels-pred_labels)))/len(test_vectors)*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_gallery(images, true_titles, pred_titles, h, w, n_row=5, n_col=5):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        image = test_vectors[i].reshape((8,8))\n",
    "        plt.imshow(image, cmap=plt.cm.gray_r)\n",
    "        plt.title('Pred='+str(pred_titles[i]*10), size=9)\n",
    "        plt.xlabel('Actual='+str(true_titles[i]*10), size=9)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "plot_gallery(test_vectors, test_labels, pred_labels, h,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>DO THIS:</font>** Modify the number of input, hidden and output layers to get the best fit of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** What is your best result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"NN_Libraries\"></a>\n",
    "# 5. Finding/Using Neural Networks Libraries\n",
    "In this section we will repeat both examples from above (Grades and Digits) using a python neural network library.  \n",
    "\n",
    "&#9989; **<font color=red>DO THIS:</font>** - As a group, find examples of neural network packages in python.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List links to the python libraries you found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>DO THIS:</font>** - Pick a package (or packages) you find interesting and get them working in this notebook.  I suggest that each group member try to pick a different package and spend about 10 minutes trying to install and get it working. After about 10 minutes compare notes and pick the one the group will think is the easiest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** What package did you pick.  Please include any installation code needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your installation code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "&#9989; **<font color=red>DO THIS:</font>** - Create an example to demonstrate that the Neural Network is working.  Preferably use an example that comes with the provided NN Package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your example code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "&#9989; **<font color=red>DO THIS:</font>** - Reproduce the results from the \"Grade\" example above using ```X``` and ```y```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your Grade example code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "&#9989; **<font color=red>DO THIS:</font>** - Reproduce the results from the \"Digits\" example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your Digits example code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Data error\", np.sum(np.sqrt((test_labels - pred_labels)*(test_labels-pred_labels)))/len(test_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_gallery(images, true_titles, pred_titles, h, w, n_row=5, n_col=5):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        image = test_vectors[i].reshape((8,8))\n",
    "        plt.imshow(image, cmap=plt.cm.gray_r)\n",
    "        plt.title('Pred='+str(pred_titles[i]), size=9)\n",
    "        plt.xlabel('Actual='+str(true_titles[i]), size=9)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "plot_gallery(test_vectors, test_labels, pred_labels, h,w)\n",
    "\n",
    "##ANSWER##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** What settings worked the best for the 'Digits' data? How did you find these settings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer to the above question here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** What part did you have the most trouble figuring out to get this assignment working?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Put your answer to the above question here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Congratulations, we're done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course Resources:\n",
    "\n",
    "- [Syllabus](https://docs.google.com/document/d/e/2PACX-1vTW4OzeUNhsuG_zvh06MT4r1tguxLFXGFCiMVN49XJJRYfekb7E6LyfGLP5tyLcHqcUNJjH2Vk-Isd8/pub)\n",
    "- [Preliminary Schedule](https://docs.google.com/spreadsheets/d/e/2PACX-1vRsQcyH1nlbSD4x7zvHWAbAcLrGWRo_RqeFyt2loQPgt3MxirrI5ADVFW9IoeLGSBSu_Uo6e8BE4IQc/pubhtml?gid=2142090757&single=true)\n",
    "- [D2L Page](https://d2l.msu.edu/d2l/home/912152)\n",
    "- [Git Repository](https://gitlab.msu.edu/colbrydi/cmse802-s20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#169; Copyright 2020,  Michigan State University Board of Trustees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
